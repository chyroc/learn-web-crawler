# Scrapy 爬虫初始化、爬取入门

## Scrapy

- Scrapy 是一个爬虫框架
- [文档](https://docs.scrapy.org/en/latest/intro/overview.html)

### 安装

```shell script
# 安装
pip install scrapy
```

### 运行一个爬虫

进入目录：

```shell script
cd <some-dir>/learn-web-crawler/codes/douban_book
```

然后执行：

```shell script
scrapy crawl douban_book_tag -o douban_book_tag.json
```

上面的代码会执行目录 `<some-dir>/learn-web-crawler/codes/douban_book/spiders` 中的 `douban_book_tag.py` 文件

- start_urls
  - 表示从哪些网址开始爬取
- def parse
  - 解析爬取的返回值
  - yield 返回一个结果

```python
import scrapy


class DoubanBookTagSpider(scrapy.Spider):
    name = 'douban_book_tag'
    start_urls = [
        'https://book.douban.com/tag/?view=cloud',
    ]
    headers = {}

    def parse(self, response):
        trs = response.xpath('//table[@class="tagCol"]/tbody/tr')
        for tr in trs:
            tds = tr.xpath('td')
            for td in tds:
                title = td.xpath('a').pop().css('::text').get()
                href = 'https://book.douban.com' + td.xpath('a').pop().attrib.get('href', '')
                count = td.xpath('b').pop().css('::text').get().replace('(', '').replace(')', '')
                yield {'title': title, 'href': href, 'count': count}

```